BERKELEY DB ENVIRONMENT CODE
============================

$Id$

This document does not apply when you are installing a bogofilter
version that has been configured to use the TDB or QDBM data base
managers.

0. Definitions ---------------------------------------------------------

Whenever ~/.bogofilter appears in the text below, this is the directory
where bogofilter keeps its data base by default. If you are overriding
this directory by configuration or environment variables, replace your
actual bogofilter data base directory.

1. Overview ------------------------------------------------------------

This bogofilter version has been upgraded to use the Berkeley DB
Transactional Data Store, to be able to recover a data base after an
application or system crash.

2. Prerequisites and Caveats -------------------------------------------

2.1 Compatibility, Berkeley DB versions

These versions are supported:

  Sleepycat Software: Berkeley DB 3.0.55: (November 15, 1999)
  Sleepycat Software: Berkeley DB 3.1.17: (July 31, 2000)
  Sleepycat Software: Berkeley DB 3.2.9: (January 24, 2001)
  Sleepycat Software: Berkeley DB 3.3.11: (July 12, 2001)
  Sleepycat Software: Berkeley DB 4.0.14: (November 18, 2001)
  Sleepycat Software: Berkeley DB 4.1.25: (December 19, 2002)
  Sleepycat Software: Berkeley DB 4.2.52: (December  3, 2003)
  Sleepycat Software: Berkeley DB 4.3.21: (November  8, 2004)

Other 3.x or 4.x versions of Berkeley DB may or may not work.

Berkeley DB versions 4.1 and newer are recommended over the previous
versions, because the newer can detect data corruptions more reliably
(through the use of checksums that detect partially written data base
pages); Berkeley DB 4.1 appears a bit slower under load than its
successors (i. e. with multiple running copies of bogofilter/bogoutil
operating on the same data base with at least one spam registration in
progress).

2.2 Upgrading from non-transactional releases of bogofilter (before 0.93)

Bogofilter should transparently upgrade the existing data base to the
new transactional data base.  Note though that upgrading will not add
checksums (see the previous section) to existing data bases, so it is
recommended that, if you are using BerkeleyDB versions 4.1 or newer,
that you dump and reload the data base to add checksums.

The dump/load cycle is necessary only the first time you upgrade from a
non-transactional to a transactional release.  Use these commands:

cd ~/.bogofilter
bogoutil -d wordlist.db >wordlist.txt
mv wordlist.db wordlist.db.old
bogoutil -l wordlist.db <wordlist.txt

And if all commands succeeded: rm wordlist.txt

NOTE: transactional databases require large lock tables, the exact
size depends on the size of the database. If the lock table isn't
large enough, you may get errors and need to increase the lock table
size, see section 3.2 and perhaps 4.2 when you see this problem.
"bogoutil -d wordlist.db >/dev/null" can be used to check if the lock
table size is sufficient, as it will access the whole data base.

2.3 Recoverability

The ability to recover the data base after a crash (power failure!)
depends on data being written to the disk (or a battery-backed write
cache) _immediately_ rather than delayed to be written later.

Common disk drives in current PCs and MACs are of the ATA or SATA kind
and usually ship with their write cache enabled. They write fast, but
can lose or corrupt up to a few MB of data when the power fails.
Note: This problem is not specific to bogofilter.

It is possible to sacrifice a bit bit of the the write speed and get
reliability in turn, by switching off the disk's write cache (see
appendix A for instructions).

Switching the write cache off may however adversely affect the
performance below acceptable levels, particularly for large writes such
as recording live audio or video data to hard disk.
If performance is degraded too much, consider getting a separate disk
drive and using one for fast writes (with the write cache one) and one
for reliable writes (with the write cache off, for bogofilter, mail
servers and other applications that need survive a power loss without
data loss).

2.4 Choosing a file system

If your computer saves the data on its own disk drive (a "local file
system"), BerkeleyDB should work fine. Such file systems are ext2, ext3,
ffs, jfs, hfs, hfs+, reiserfs, ufs, xfs.

Berkeley DB does not work reliably with a networked file system. AFS,
CIFS, Coda, NFS, SMBFS fall into this category.

Strictly speaking, with BerkeleyDB 4.0 and older versions, the data base
block size must be written atomically. The bogofilter maintainers are
not currently aware of a file system that meets this requirement and is
production quality at the same time.

2.5 Do make backups!

The transactional data store is no good if the disk drive has become
inaccessible (which happens after some months or years with every
drive), so you _must_ back up your data base regularly (see the
db_archive utility for additional documentation of a "hot" backup),
bogofilter cannot, of course, guess data that got lost through a hard
drive fault.

Although backup strategies are beyond the scope of this document, be
sure to store fresh backups of important data outside of your house
regularly.

3. Use and troubleshooting ---------------------------------------------

3.1 LOG FILE HANDLING

The Berkeley DB Transactional Data Store uses log files to store data
base changes so that they can be rolled back or restored after an
application crash.

The logs of the transactional data store, log.NNNNNNNNNN files of up to
10 MB in size (in the default configuration), can consume considerable
amounts of disk space and many users wish to purge or compress these log
files. These can safely be handled with BerkeleyDB's db_checkpoint and
db_archive utilities, which should be run in this order:

- db_checkpoint migrates written-ahead data from the log files into the
  data base, and places a checkpoint which will speed up data base
  recovery, for instance after a premature bogofilter abort.

- db_archive allows to identify log files that are no longer in use so
  that you can compress or remove them.

Before choosing to remove log files, be sure to read the db_archive
documentation that ships with BerkeleyDB, because removing logs has an
impact on recoverability and can render your data base unrecoverable.

The db_archive documentation also contains suggestions for several
backup strategies.

3.2 LOCK TABLE EXHAUSTION

One common failure case is known:

Problem: Operations that affect large parts of the data base or the data
	 base as a whole (bogoutil usually) may require many locks and
	 exhaust the maximum number of locks or the maximum number of
	 locked objects that the Berkeley DB environments support.

Symptom: Operations abort with "out of memory" although the machine has
	 plenty of RAM and/or swap.

	 Operations report lock or object table exhaustion and abort.

Cause:	 Natural data base growth.

Fix:     Resize the lock tables. It is easy and requires these two
	 steps: (In the next steps, adjust the ~/.bogofilter path if you
	 don't have the data base in its default location)

a. Create a ~/.bogofilter/DB_CONFIG file (in the same directory as your
   wordlist.db file) that looks like this:

set_lk_max_objects  32768
set_lk_max_locks    32768

You may need to adjust these figures. You will need up to one lock per
data base page and a bit of headroom for future training -- see section
4.2 below to determine the size of the data base and data base page.

b. Run bogoutil -f ~/.bogofilter (use the path from step a, omitting
   the /DB_CONFIG part).

4. Other Information of Interest ---------------------------------------

4.1 GENERAL INFORMATION

Berkeley DB keeps some additional statistics about locking, caching and
their efficiency. These can be obtained by running the db_stat utility:

db_stat -h ~/.bogofilter -d wordlist.db # data base statistics

db_stat -h ~/.bogofilter -e # environment statistics
db_stat -h ~/.bogofilter -c # lock statistics - needed for lock resizing
db_stat -h ~/.bogofilter -m # buffer pool statistics
db_stat -h ~/.bogofilter -l # log statistics
db_stat -h ~/.bogofilter -t # transaction statistics

Note that statistics may disappear when the data base is recovered. They
will reappear after running bogofilter and are the more reliable the
more often bogofilter has been used since the last recovery.

You MUST NOT remove files named __db.NNN and log.NNNNNNNNNN - where
NNN are numbers - in the ~/.bogofilter directory.
REMOVING THESE FILES CAUSES DATA BASE CORRUPTION
(there is one exception, see below)

These can contain update data for the data base that must be still
written back to the wordlist.db file - this happens when there are many
concurrent processes alongside a registration process.

Exception: after reading the Berkeley DB documentation for the
db_archive utility and using that utility, you may be able to remove
some of the log.NNNNNNNNNN files. This may be necessary to reclaim disk
space, but you must strictly adhere to the Berkeley DB documentation
lest you risk your data base become unrecoverable in case of trouble.

WARNING: If you need to copy data base files,
	 DO NOT USE cp, BUT DO USE dd instead and give it a block size
	 that matches the data base's block size, which can be found by
	 running db_stat with -d option as shown above.

4.2 SPECIFIC INFORMATION ON RESIZING THE LOCK TABLES

In all the commands shown below, replace the ~/.bogofilter path by the
name of the directory holding your wordlist.db file.

a. Determine the data base size:

ls -l ~/.bogofilter/wordlist.db

b. Determine the data base page size:

db_stat -h ~/.bogofilter/ -d wordlist.db
The relevant line has "database page size"

c. The number of locks and lock objects needed is the data base size
divided by the data base page size, rounded up generously, for example:

(output from step a)
-rw-r--r--    1 joe      users    15360000 2004-05-11 12:25 wordlist.db

(output from step b)
53162   Btree magic number.
8       Btree version number.
Flags:
2       Minimum keys per-page.
4096    Underlying database page size.
3       Number of levels in the tree.
...

Hence: 15360000 / 4096 = 3750

d. Round up, 4096 may be adequate if you train seldomly, use
higher values if you train often or in preparation of training on a
large mailbox. Higher values make your lock region, usually __db.004,
larger, but allow for larger data bases. Lower values save disk space
but may require you to to resize the lock region more often.

e. Use this rounded-up figure for both of the the two DB_CONFIG file
   lines mentioned in section 3.1

f. run bogoutil -f ~/.bogofilter

Bogofilter will re-create the lock tables automatically
the next time it is run.

A. Switching the disk drive's write cache off and on -------------------

A.1 Introduction

You need to determine the name of the disk device and its type.
Type "mount", you'll usually get an output that contains lines like
these; find the "on /home" if you have it, if you don't check for "on
/usr" if you have it, or finally, resort to looking at the "on /" line.

From this line, look at the left hand column, usually starting with /dev.

If you have FreeBSD, skip to section A.3 now.

A.2 Switching the write cache off or on in Linux

In this line you've found (see previous section A.1), you'll usually find
something that starts with /dev/hda, /dev/hde or /dev/sda in the left
hand column of that line, you can ignore the trailing number. /dev/hd*
means ATA, /dev/sd* means SCSI.

If the drive name starts with /dev/hd, type the following line, but
replace hda by hde or what else you may have found:

/sbin/hdparm -W0 /dev/hda
                 (replace -W0 by -W1 to reenable the write cache)

If your drive name starts with /dev/sd, use the graphical scsi-config
utility and add a blank the device name on the command line; for
example:

scsi-config /dev/sda

You can "try changes" (they will be forgotten the next time the computer
is switched off) or "save changes" (settings will be saved permanently);
you can use the same utility to restore the previous setting or load
manufacturer defaults. Skip to section 2.4.

What is this scsi-config?

The scsi-config command is a Tk script, delivered with the scsiinfo
package.  At the time of writing, scsiinfo can be found at
ftp://tsx-11.mit.edu/pub/linux/ALPHA/scsi/scsiinfo-1.7.tar.gz .

For users who don't run X on their mail servers, there is also a
command-line utility, scsiinfo, in the package.  Setting parameters
with scsiinfo is a bit hairy, but the following sequence worked for two
of us who tried it (back up your drive first):

# get current disk settings and turn off the write cache
# (substitute the appropriate device for /dev/sda in all these commands)
parms=`scsiinfo -cX /dev/sda | sed 's/^./0/'`

# write the parameters back to the hard drive's current settings
# this needs to be put in a boot script
scsiinfo -cXR /dev/sda $parms

# if you don't want to put this in a boot script, you can alternatively
# save the parameters to the hard drive's settings area:
scsiinfo -cXRS /dev/sda $parms

You did back up your drive before trying that, right? :)


A.3 Switching the write cache off in FreeBSD

Have you read section A.1 already? You should have.

In this line you've found (see section A.1), you'll usually have a line
that starts with /dev/ad0, /dev/wd0 (either means you have ATA) or
/dev/da0 (which means you have SCSI).

If you have ATA, add the line

      hw.ata.wc="0"

to /boot/loader.conf.local, shut down all applications and reboot. (To
revert the change, remove the line, shut down all applications and
reboot.)

If you have SCSI, you'll need to decide if you want the setting until the next
reboot, or permanent (the permanent setting can be changed back, don't worry).
In either case, omit the leading /dev and trailing s<NUMBER><LETTER> parts
(/dev/da0s1a -> da0; /dev/da4s3f -> da4). Replace da0 by your device name in
these examples, and leave out the part in parentheses:

 camcontrol modepage da0 -m8 -e -P0 (effective until computer is switched off)
 camcontrol modepage da0 -m8 -e -P3 (save parameters permanently)

camcontrol will open a temporary file with a WCE: line on top. Edit the
figure to read 0 (cache disabled) or 1 (cache enabled), then save the
file and exit the editor.
